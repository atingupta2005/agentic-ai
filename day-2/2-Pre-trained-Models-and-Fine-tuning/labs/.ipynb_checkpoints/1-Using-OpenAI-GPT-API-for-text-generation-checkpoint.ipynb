{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cb31dd",
   "metadata": {},
   "source": [
    "# 🛠 Pre-trained Models and Fine-Tuning\n",
    "\n",
    "This guide walks you through two hands-on labs:  \n",
    "1. Using OpenAI’s GPT API for text generation  \n",
    "2. Fine-tuning a BERT model for sentiment analysis on a real-world dataset  \n",
    "\n",
    "## Text Generation with OpenAI’s GPT API\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- An OpenAI API key (set as environment variable `OPENAI_API_KEY`)  \n",
    "- Install the `openai` library:  \n",
    "  ```bash\n",
    "  pip install openai\n",
    "  ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c420f2b4-6750-4ea7-96f2-af4fa8bbc0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.97.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/venvs/jupyterhub/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Downloading openai-1.97.1-py3-none-any.whl (764 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.4/764.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, distro, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [openai]2m3/4\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distro-1.9.0 jiter-0.10.0 openai-1.97.1 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e94b2f2-1f27-48ba-a8b7-ae5418c1dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2a015c-19a5-4043-9207-a4144329d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env from home directory\n",
    "dotenv_path = os.path.expanduser(\"~/.env\")\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# Get API key from env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05615c49-6038-49ea-b140-612162cbf1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert \"OPENAI_API_KEY\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb82261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "def generate_text(prompt: str,\n",
    "                  model: str = \"gpt-3.5-turbo\",  # chat models only\n",
    "                  max_tokens: int = 100,\n",
    "                  temperature: float = 0.7,\n",
    "                  top_p: float = 1.0,\n",
    "                  n_samples: int = 1):\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        n=n_samples\n",
    "    )\n",
    "\n",
    "    return [choice.message.content.strip() for choice in response.choices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f8203e-ec6a-4413-ac53-37b85bd2ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What do you think about future life quality?\"\n",
    "outputs = generate_text(prompt, max_tokens=50, temperature=0.5, n_samples=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73a08f3-f626-4e3d-b58d-69d933faaa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample 1 ===\n",
      "I think that the future holds great potential for improved life quality for many people. With advancements in technology, healthcare, and environmental sustainability, we have the opportunity to create a more equitable and sustainable world. However, it will require collective effort and collaboration to\n",
      "\n",
      "=== Sample 2 ===\n",
      "I believe that future life quality has the potential to greatly improve with advancements in technology, healthcare, and environmental sustainability. However, it will also depend on how we address issues such as income inequality, access to education and healthcare, and climate change. Overall\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(outputs, 1):\n",
    "    print(f\"\\n=== Sample {i} ===\\n{text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17eb827",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Run it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f6d1f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Experimenting with Parameters\n",
    "\n",
    "- **`temperature`**: Higher values (0.8–1.0) → more creative outputs; lower (0.2–0.5) → more focused.  \n",
    "- **`max_tokens`**: Limits response length.  \n",
    "- **`top_p`** (nucleus sampling): Restricts vocabulary to cumulative probability _p_.  \n",
    "- **`n`**: Number of samples to generate per prompt.\n",
    "\n",
    "> 💡 Try generating three variations of a product description by setting `n_samples=3` and compare diversity.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Advanced: Chat Completions (GPT-3.5 / GPT-4)\n",
    "\n",
    "OpenAI’s chat endpoint uses a list of messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a37b2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several benefits of electric vehicles (EVs) compared to traditional internal combustion engine vehicles:\n",
      "\n",
      "1. Environmental impact: EVs produce zero tailpipe emissions, reducing air pollution and greenhouse gas emissions. This helps combat climate change and improves air quality.\n",
      "\n",
      "2. Cost savings: EVs are generally cheaper to operate and maintain compared to conventional vehicles. Electricity is often less expensive than gasoline, and EVs have fewer moving parts, reducing maintenance costs.\n",
      "\n",
      "3. Energy efficiency: EVs are more energy-efficient than traditional vehicles, as electric motors convert a higher percentage of energy from the grid to power the wheels.\n",
      "\n",
      "4. Performance: Electric motors provide instant torque, resulting in quick acceleration and a smooth driving experience. EVs are also quieter than traditional vehicles.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain the benefits of electric vehicles.\"}\n",
    "    ],\n",
    "    max_tokens=150,\n",
    "    temperature=0.6\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869d6082",
   "metadata": {},
   "source": [
    "> 🔍 Notice how you can steer tone and style with the “system” message.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
