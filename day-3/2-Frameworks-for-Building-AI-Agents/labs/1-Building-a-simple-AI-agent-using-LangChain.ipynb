{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc12820",
   "metadata": {},
   "source": [
    "# ðŸ­ Lab: Building a Simple AI Agent Using LangChain\n",
    "\n",
    "## Lab Objectives\n",
    "By the end of this lab, you will:\n",
    "1. Set up a Python environment with LangChain and an LLM provider (OpenAI).\n",
    "2. Implement a custom â€œWikipedia Searchâ€ tool.\n",
    "3. Instantiate a LangChain agent that dynamically chooses tools.\n",
    "4. Interact with your agent in a REPL loop.\n",
    "5. Extend the agent with memory to preserve context.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.8+  \n",
    "- An OpenAI API key (exported as `OPENAI_API_KEY`)  \n",
    "- Basic familiarity with Python and REST APIs  \n",
    "- (Optional) Git installed for cloning examples\n",
    "\n",
    "---\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "1. Create and activate a virtual environment:\n",
    "   ```bash\n",
    "   python -m venv venv\n",
    "   source venv/bin/activate       # macOS/Linux\n",
    "   venv\\Scripts\\activate          # Windows PowerShell\n",
    "   ```\n",
    "\n",
    "2. Install dependencies:\n",
    "   ```bash\n",
    "   pip install langchain openai requests python-dotenv\n",
    "   ```\n",
    "\n",
    "3. In your project folder, create a file `.env` containing:\n",
    "   ```\n",
    "   OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX\n",
    "   ```\n",
    "\n",
    "4. Create a Python file `agent_lab.py` and add:\n",
    "   ```python\n",
    "   import os\n",
    "   from dotenv import load_dotenv\n",
    "\n",
    "   load_dotenv()\n",
    "   OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## Task 1: Implement the Wikipedia Search Tool\n",
    "\n",
    "1. Add imports at top of `agent_lab.py`:\n",
    "   ```python\n",
    "   import requests\n",
    "   from langchain import Tool\n",
    "   ```\n",
    "\n",
    "2. Define a function to fetch a Wikipedia summary:\n",
    "   ```python\n",
    "   def wiki_search(topic: str) -> str:\n",
    "       url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{topic}\"\n",
    "       resp = requests.get(url)\n",
    "       if resp.status_code != 200:\n",
    "           return \"No article found.\"\n",
    "       data = resp.json()\n",
    "       return data.get(\"extract\", \"No summary available.\")\n",
    "   ```\n",
    "\n",
    "3. Wrap it as a LangChain Tool:\n",
    "   ```python\n",
    "   wiki_tool = Tool(\n",
    "       name=\"wiki_search\",\n",
    "       func=wiki_search,\n",
    "       description=\"Use this tool to get a summary of any Wikipedia topic.\"\n",
    "   )\n",
    "   ```\n",
    "\n",
    "4. Test the tool:\n",
    "   ```python\n",
    "   if __name__ == \"__main__\":\n",
    "       print(wiki_search(\"LangChain\"))\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## Task 2: Initialize the LLM\n",
    "\n",
    "1. Import and instantiate an OpenAI LLM wrapper:\n",
    "   ```python\n",
    "   from langchain.llms import OpenAI\n",
    "\n",
    "   llm = OpenAI(\n",
    "       temperature=0.2,\n",
    "       openai_api_key=OPENAI_API_KEY\n",
    "   )\n",
    "   ```\n",
    "\n",
    "2. Test a basic prompt:\n",
    "   ```python\n",
    "   if __name__ == \"__main__\":\n",
    "       print(llm(\"Explain LangChain in one sentence.\"))\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## Task 3: Create and Run the Agent\n",
    "\n",
    "1. Import the agent initializer:\n",
    "   ```python\n",
    "   from langchain import initialize_agent, AgentType\n",
    "   ```\n",
    "\n",
    "2. Instantiate a zero-shot agent with your tool:\n",
    "   ```python\n",
    "   agent = initialize_agent(\n",
    "       tools=[wiki_tool],\n",
    "       llm=llm,\n",
    "       agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "       verbose=True\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. Add an interactive REPL loop at the bottom:\n",
    "   ```python\n",
    "   if __name__ == \"__main__\":\n",
    "       while True:\n",
    "           query = input(\"\\nEnter your question (or 'exit'): \")\n",
    "           if query.lower() == \"exit\":\n",
    "               break\n",
    "           print(agent.run(query))\n",
    "   ```\n",
    "\n",
    "4. Run the agent:\n",
    "   ```bash\n",
    "   python agent_lab.py\n",
    "   ```\n",
    "   - **Try queries**:  \n",
    "     - â€œWhat is the capital of France?â€  \n",
    "     - â€œTell me about the Mars Rover.â€\n",
    "\n",
    "---\n",
    "\n",
    "## Task 4: Add Conversation Memory\n",
    "\n",
    "1. Install a memory module:\n",
    "   ```bash\n",
    "   pip install langchain[embeddings]\n",
    "   ```\n",
    "\n",
    "2. Add imports and memory setup:\n",
    "   ```python\n",
    "   from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "   memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "   ```\n",
    "\n",
    "3. Re-initialize the agent with memory:\n",
    "   ```python\n",
    "   agent = initialize_agent(\n",
    "       tools=[wiki_tool],\n",
    "       llm=llm,\n",
    "       agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "       memory=memory,\n",
    "       verbose=True\n",
    "   )\n",
    "   ```\n",
    "\n",
    "4. Relaunch and observe that follow-up questions maintain context:\n",
    "   ```text\n",
    "   You: Who is Ada Lovelace?\n",
    "   Agent: Ada Lovelace isâ€¦\n",
    "   You: When did she live?\n",
    "   Agent: She lived from 1815 to 1852.\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## Task 5: Extend with a Calculator Tool\n",
    "\n",
    "1. Define a simple calculator:\n",
    "   ```python\n",
    "   def calc(expression: str) -> str:\n",
    "       try:\n",
    "           return str(eval(expression, {}, {}))\n",
    "       except Exception:\n",
    "           return \"Invalid calculation.\"\n",
    "   ```\n",
    "\n",
    "2. Wrap it as a tool:\n",
    "   ```python\n",
    "   calc_tool = Tool(\n",
    "       name=\"calculator\",\n",
    "       func=calc,\n",
    "       description=\"Evaluate arithmetic expressions.\"\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. Reinitialize the agent with both tools:\n",
    "   ```python\n",
    "   agent = initialize_agent(\n",
    "       tools=[wiki_tool, calc_tool],\n",
    "       llm=llm,\n",
    "       agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "       memory=memory,\n",
    "       verbose=True\n",
    "   )\n",
    "   ```\n",
    "\n",
    "4. Test mixed queries:\n",
    "   ```text\n",
    "   You: What is 128 * 7?\n",
    "   Agent: 896\n",
    "   You: And who is Alan Turing?\n",
    "   Agent: â€¦\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## Lab Deliverables\n",
    "\n",
    "- `agent_lab.py` containing:\n",
    "  - Wikipedia search tool  \n",
    "  - Calculator tool  \n",
    "  - OpenAI LLM initializer  \n",
    "  - Agent with memory  \n",
    "  - REPL loop  \n",
    "- Screenshots or logs demonstrating:\n",
    "  - Tool calls (wiki and calculator)  \n",
    "  - Memory in follow-up queries  \n",
    "\n",
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "1. How does the agent decide which tool to invoke?  \n",
    "2. What are the benefits of adding memory to the agent?  \n",
    "3. How might you add error handling or retries for failed API calls?  \n",
    "4. Propose an additional tool (e.g., weather, stock prices) and sketch its implementation.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps & Extensions\n",
    "\n",
    "- Swap OpenAI for a local Hugging Face model backend.  \n",
    "- Persist memory in a Redis or SQL store.  \n",
    "- Build a multi-agent system: one agent scrapes data, another analyzes it.  \n",
    "- Integrate function-calling APIs (e.g., OpenAI Functions) for richer tool definitions."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
