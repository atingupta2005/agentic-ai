{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f283b330",
   "metadata": {},
   "source": [
    "# üåê Connecting AI Agents to External APIs  \n",
    "_A hands‚Äêon guide to endowing your AI agents with real‚Äêworld knowledge via Google Search and Wolfram Alpha integrations._\n",
    "\n",
    "## 1. Introduction  \n",
    "\n",
    "Most AI agents excel at language understanding but lack up-to-the-minute world knowledge or precise computational abilities. By hooking into external APIs‚Äîlike Google Search for web data and Wolfram Alpha for math, scientific facts, and structured knowledge‚Äîagents become far more capable.  \n",
    "\n",
    "In this lab, you will:  \n",
    "- Acquire API credentials  \n",
    "- Wrap each API as a **LangChain Tool**  \n",
    "- Assemble an agent that chooses between search and computation  \n",
    "- Handle errors, timeouts, and caching  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Prerequisites  \n",
    "\n",
    "- Python 3.8+ installed  \n",
    "- Familiarity with virtual environments  \n",
    "- Basic knowledge of LangChain (or similar agent framework)  \n",
    "- `pip` access to install packages  \n",
    "- Accounts and API keys for:  \n",
    "  - SerpAPI (Google Search)  \n",
    "  - Wolfram Alpha  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Why External APIs?  \n",
    "\n",
    "- **Google Search** gives you live web results, news, definitions, and obscure facts.  \n",
    "- **Wolfram Alpha** excels at math, unit conversions, scientific constants, and data queries.  \n",
    "- **Agents** can automatically decide which tool to use:  \n",
    "  - ‚ÄúWhen was the Eiffel Tower built?‚Äù ‚Üí Google Search  \n",
    "  - ‚ÄúCompute 12 inches in centimeters.‚Äù ‚Üí Wolfram Alpha  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Google Search API Integration  \n",
    "\n",
    "### 4.1. Obtaining a SerpAPI Key  \n",
    "\n",
    "1. Sign up at https://serpapi.com/  \n",
    "2. Copy your **API Key** from the dashboard.  \n",
    "3. Store it in your environment:\n",
    "\n",
    "   ```bash\n",
    "   export SERPAPI_API_KEY=\"your_serpapi_key\"\n",
    "   ```\n",
    "\n",
    "### 4.2. Installing Dependencies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install langchain serpapi python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75df14f",
   "metadata": {},
   "source": [
    "### 4.3. Building a Google Search Tool  \n",
    "\n",
    "In `agent_search.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import Tool\n",
    "from serpapi import GoogleSearch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "SERPAPI_API_KEY = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "def google_search(query: str) -> str:\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": query,\n",
    "        \"api_key\": SERPAPI_API_KEY,\n",
    "        \"num\": \"5\"\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict().get(\"organic_results\", [])\n",
    "    if not results:\n",
    "        return \"No results found.\"\n",
    "    # Concatenate top 3 titles + snippets\n",
    "    summary = []\n",
    "    for res in results[:3]:\n",
    "        title = res.get(\"title\")\n",
    "        snippet = res.get(\"snippet\")\n",
    "        summary.append(f\"{title}: {snippet}\")\n",
    "    return \"\\n\\n\".join(summary)\n",
    "\n",
    "google_tool = Tool(\n",
    "    name=\"google_search\",\n",
    "    func=google_search,\n",
    "    description=\"Fetch top web results for a query via Google Search API.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac08651",
   "metadata": {},
   "source": [
    "### 4.4. Testing the Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf35200",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(google_search(\"latest Mars rover discoveries\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656be2c",
   "metadata": {},
   "source": [
    "Expect 3‚Äì5 summarized entries from Google‚Äôs organic results.\n",
    "\n",
    "### 4.5. LangChain Example: Web-Enabled QA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import initialize_agent, AgentType\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Create agent with only the Google tool\n",
    "agent = initialize_agent(\n",
    "    tools=[google_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Sample run\n",
    "print(agent.run(\"What are the three most recent NASA missions to the Moon?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a756a",
   "metadata": {},
   "source": [
    "Agent will detect the need for web data and call `google_search`.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Wolfram Alpha API Integration  \n",
    "\n",
    "### 5.1. Getting a Wolfram Alpha AppID  \n",
    "\n",
    "1. Sign up at https://developer.wolframalpha.com/portal/myapps/  \n",
    "2. Create a new **Simple App** and obtain the **AppID**.  \n",
    "3. Store it securely:\n",
    "\n",
    "   ```bash\n",
    "   export WOLFRAM_APP_ID=\"your_app_id\"\n",
    "   ```\n",
    "\n",
    "### 5.2. Installing Dependencies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51561b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install wolframalpha langchain python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bed10e5",
   "metadata": {},
   "source": [
    "### 5.3. Building a Wolfram Alpha Tool  \n",
    "\n",
    "In `agent_compute.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import Tool\n",
    "import wolframalpha\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "APP_ID = os.getenv(\"WOLFRAM_APP_ID\")\n",
    "client = wolframalpha.Client(APP_ID)\n",
    "\n",
    "def wolfram_query(question: str) -> str:\n",
    "    res = client.query(question)\n",
    "    # Extract pod titles and plaintext answers\n",
    "    answers = []\n",
    "    for pod in res.pods:\n",
    "        title = pod.title\n",
    "        text = \"\".join([sub.text for sub in pod.subpods if sub.text])\n",
    "        if text:\n",
    "            answers.append(f\"{title}: {text}\")\n",
    "    return \"\\n\\n\".join(answers) or \"No answer available.\"\n",
    "\n",
    "wa_tool = Tool(\n",
    "    name=\"wolfram_alpha\",\n",
    "    func=wolfram_query,\n",
    "    description=\"Compute answers using Wolfram Alpha API.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce7b17",
   "metadata": {},
   "source": [
    "### 5.4. Testing the Wolfram Alpha Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(wolfram_query(\"integrate x^2 sin(x) dx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d5c5ac",
   "metadata": {},
   "source": [
    "Should return symbolic integration result with step titles.\n",
    "\n",
    "### 5.5. LangChain Example: Math & Facts Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ddd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import initialize_agent, AgentType\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[wa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(agent.run(\"How far is Mercury from the Sun in astronomical units?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687632f2",
   "metadata": {},
   "source": [
    "Agent chooses the Wolfram tool for precise scientific data.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Combining Tools in One Agent\n",
    "\n",
    "Bring both `google_tool` and `wa_tool` together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394efb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools=[google_tool, wa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Mixed query example\n",
    "print(agent.run(\"What is 15% of 350? Also, summarize the dictator Octavian in two sentences.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd05e408",
   "metadata": {},
   "source": [
    "- For ‚Äú15% of 350?‚Äù ‚Üí calls Wolfram Alpha  \n",
    "- For ‚ÄúOctavian‚Äù ‚Üí calls Google Search\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Error Handling & Rate-Limiting\n",
    "\n",
    "1. **API Errors:** Wrap calls in `try/except` and return user-friendly messages.  \n",
    "2. **Rate Limits:** Implement simple caching (in-memory or Redis) for repeated queries.  \n",
    "3. **Timeouts:** Use `requests` timeouts:\n",
    "\n",
    "   ```python\n",
    "   resp = requests.get(url, timeout=5)\n",
    "   ```\n",
    "\n",
    "4. **Retries:** Use `tenacity` for robust retry logic:\n",
    "\n",
    "   ```python\n",
    "   from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "\n",
    "   @retry(wait=wait_exponential(min=1, max=10), stop=stop_after_attempt(3))\n",
    "   def google_search(...):\n",
    "       # call API\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Best Practices\n",
    "\n",
    "- **Keep API Keys Secret:** Never commit `.env` to source control.  \n",
    "- **Use Dedicated Service Accounts:** Limit permissions and monitor usage.  \n",
    "- **Cache Results:** Web searches often repeat. Cache to reduce cost and latency.  \n",
    "- **Limit Output Size:** Summarize or truncate long responses.  \n",
    "- **Monitor Costs:** APIs charge per request or token‚Äîtrack your usage.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Next Steps & Extensions\n",
    "\n",
    "- Swap SerpAPI with **Google Programmable Search** or **Bing Search**.  \n",
    "- Extend Wolfram tool to parse images or unit conversions.  \n",
    "- Build a **hybrid agent** that also uses a local knowledge base (vector store).  \n",
    "- Integrate **OpenAI Function Calling** for more structured API usage.  \n",
    "- Deploy your agent as a web service with **FastAPI** or **Flask**.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Appendix: Full Example Code\n",
    "\n",
    "See `agent_search.py` and `agent_compute.py` for full implementations, plus a combined `main.py` that ties everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ed896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import initialize_agent, AgentType\n",
    "from agent_search import google_tool\n",
    "from agent_compute import wa_tool\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI(temperature=0.1)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[google_tool, wa_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def chat():\n",
    "    print(\"Agent ready. Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        q = input(\"You: \")\n",
    "        if q.lower() == \"exit\":\n",
    "            break\n",
    "        print(\"Agent:\", agent.run(q), \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62094b9c",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
