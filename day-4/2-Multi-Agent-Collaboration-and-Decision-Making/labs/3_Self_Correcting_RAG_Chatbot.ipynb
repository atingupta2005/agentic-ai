{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Building a Self-Correcting RAG Chatbot with a UI\n",
    "\n",
    "In this lab, we will build a complete, interactive application. The goal is to create a personal chatbot that answers questions based on provided documents (a PDF and a text file). This technique is a form of Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "We will then implement advanced agentic patterns like **Reflection** and **Self-Correction** from scratch, where a second AI agent evaluates the chatbot's answers and forces a retry if the quality is low. Finally, we'll wrap the entire application in a web-based user interface using Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup: Your Personal Context\n",
    "\n",
    "This chatbot is designed to represent a specific person. To personalize it, please do the following:\n",
    "\n",
    "1.  **Replace `profile.pdf`**: In the `me` folder, replace the existing `profile.pdf` with a PDF of your own resume or LinkedIn profile.\n",
    "2.  **Update `summary.txt`**: Edit the `me/summary.txt` file with a brief, third-person summary of your professional background.\n",
    "3.  **Update `your_name`**: Change the value of the `your_name` variable in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "# PyPDF is used for reading text from PDF files.\n",
    "# Gradio is used for creating the web UI.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration and API Clients ===\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# This is the primary client for the chatbot agent.\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# We will use a separate client for the evaluator agent, in this case, Google's Gemini.\n",
    "# This demonstrates how different models can be used for different tasks in an agentic system.\n",
    "gemini_client = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Context from Files (Retrieval-Augmented Generation)\n",
    "\n",
    "We will read the text from the PDF and the summary file. This content will be injected into our system prompt, giving the chatbot the necessary context to answer questions accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Personal Information ===\n",
    "# IMPORTANT: Change this to your name.\n",
    "your_name = \"Atin Gupta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the PDF file page by page and concatenate the text.\n",
    "try:\n",
    "    reader = PdfReader(\"me/profile.pdf\")\n",
    "    pdf_context = \"\"\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            pdf_context += text\n",
    "    print(\"Successfully loaded PDF context.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: me/profile.pdf not found. Please add your profile PDF.\")\n",
    "    pdf_context = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the summary text file.\n",
    "try:\n",
    "    with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        summary_context = f.read()\n",
    "    print(\"Successfully loaded summary context.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: me/summary.txt not found. Please add your summary file.\")\n",
    "    summary_context = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Agent Personas (System Prompts)\n",
    "\n",
    "We need two distinct personas: one for the chatbot agent and one for the evaluator agent. These are defined through detailed system prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona for the main chatbot agent.\n",
    "chatbot_system_prompt = f\"\"\"You are a helpful AI assistant acting as {your_name}. \n",
    "You are answering questions on {your_name}'s personal website. \n",
    "Your primary goal is to represent {your_name} faithfully and professionally, as if talking to a potential client, recruiter, or colleague.\n",
    "Use the provided summary and profile information to answer questions about {your_name}'s career, skills, and experience.\n",
    "If you do not know the answer to a question based on the context provided, it is better to say that you don't have that information.\n",
    "--- CONTEXT --- \n",
    "## Summary:\n",
    "{summary_context}\n",
    "\n",
    "## Profile Details:\n",
    "{pdf_context}\n",
    "--- END CONTEXT ---\n",
    "Now, please chat with the user, always staying in character as {your_name}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona for the evaluator agent.\n",
    "evaluator_system_prompt = f\"\"\"You are a strict quality control evaluator. Your task is to decide if an AI agent's response is acceptable.\n",
    "The agent is playing the role of {your_name} and must be professional, engaging, and factually consistent with the provided context.\n",
    "Evaluate the agent's most recent response in the context of the user's question and the conversation history.\n",
    "The response is UNACCEPTABLE if it is evasive, unprofessional, factually incorrect, or hallucinates information not present in the context.\n",
    "The response is ACCEPTABLE if it is helpful, professional, and grounded in the provided information.\n",
    "--- CONTEXT ---\n",
    "## Summary:\n",
    "{summary_context}\n",
    "\n",
    "## Profile Details:\n",
    "{pdf_context}\n",
    "--- END CONTEXT ---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Self-Correction Workflow\n",
    "\n",
    "This is the core of our agentic system. We will define three functions:\n",
    "1.  `chat_agent`: The main chatbot that generates the initial response.\n",
    "2.  `evaluation_agent`: The evaluator that checks the response quality.\n",
    "3.  `rerun_agent`: The agent that re-attempts the answer if the first one was rejected, using the evaluator's feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models enforce a specific JSON structure for the LLM's output.\n",
    "# This makes the output predictable and easy to parse.\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_agent(reply: str, message: str, history: list) -> Evaluation:\n",
    "    \"\"\"The agent that evaluates the chatbot's response.\"\"\"\n",
    "    print(\"--- Evaluating response... ---\")\n",
    "    \n",
    "    # Create the prompt for the evaluator.\n",
    "    evaluator_user_prompt = f\"\"\"An agent, acting as {your_name}, was asked a question by a User.\n",
    "    Conversation History: {history}\n",
    "    User's latest message: '{message}'\n",
    "    Agent's response: '{reply}'\n",
    "    Please evaluate the agent's response based on the criteria and context you were given.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluator_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": evaluator_user_prompt}\n",
    "    ]\n",
    "    \n",
    "    # Use the `.parse()` method to automatically get structured JSON output.\n",
    "    # This requires a Pydantic model (`Evaluation`) to define the schema.\n",
    "    response = gemini_client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash-latest:generateContent\", \n",
    "        messages=messages, \n",
    "        response_format=Evaluation # This is a conceptual representation; actual API might differ.\n",
    "    )\n",
    "    # A more realistic implementation might involve a function call / tool call\n",
    "    # For now, let's assume a compatible structured output feature.\n",
    "    # As a fallback, we'll manually parse a JSON string if needed.\n",
    "    try:\n",
    "        parsed_response = Evaluation.model_validate_json(response.choices[0].message.content)\n",
    "    except:\n",
    "        # Fallback for models that don't perfectly adhere to the JSON schema\n",
    "        print(\"Warning: Could not directly parse response. Assuming acceptable.\")\n",
    "        return Evaluation(is_acceptable=True, feedback=\"Could not parse evaluator response.\")\n",
    "\n",
    "    return parsed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun_agent(reply: str, message: str, history: list, feedback: str) -> str:\n",
    "    \"\"\"The agent that retries the answer after failure.\"\"\"\n",
    "    print(\"--- Rerunning with feedback... ---\")\n",
    "    \n",
    "    # The system prompt is updated with the feedback from the evaluator.\n",
    "    # This is the \"Reflection\" step, where the agent learns from its mistake.\n",
    "    rerun_system_prompt = chatbot_system_prompt + f\"\"\"\\n\\n## Previous Attempt Failed\n",
    "    Your previous answer was rejected by the quality control evaluator.\n",
    "    Your attempted answer: '{reply}'\n",
    "    Reason for rejection: '{feedback}'\n",
    "    Please try again, taking this feedback into account to generate a better, more professional, and factually accurate response.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": rerun_system_prompt}\n",
    "    ] + history + [\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the Main Chat Interface\n",
    "\n",
    "This final function orchestrates the entire workflow. It takes the user's message, gets a response, sends it to the evaluator, and triggers a rerun if necessary. This function will be connected to the Gradio UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_workflow(message: str, history: list):\n",
    "    \"\"\"The main workflow that connects all the agents.\"\"\"\n",
    "    print(f\"\\n--- New Request: {message} ---\")\n",
    "    \n",
    "    # Gradio's history format can sometimes include extra data.\n",
    "    # This line cleans it to ensure compatibility with the OpenAI API.\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "\n",
    "    # === Initial Response ===\n",
    "    print(\"--- Generating initial response... ---\")\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": chatbot_system_prompt}\n",
    "    ] + history + [\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    \n",
    "    # === Evaluation ===\n",
    "    evaluation = evaluation_agent(reply, message, history)\n",
    "    \n",
    "    # === Self-Correction ===\n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"\\n*** PASSED EVALUATION ***\")\n",
    "        return reply\n",
    "    else:\n",
    "        print(f\"\\n*** FAILED EVALUATION ***\\nFeedback: {evaluation.feedback}\")\n",
    "        final_reply = rerun_agent(reply, message, history, evaluation.feedback)\n",
    "        return final_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Gradio web interface.\n",
    "# This creates a public URL where you can interact with your chatbot.\n",
    "gr.ChatInterface(\n",
    "    chat_workflow, \n",
    "    title=f\"{your_name}'s Personal AI Assistant\",\n",
    "    description=\"Ask me questions about my professional background, skills, and experience.\",\n",
    "    examples=[\"What is your experience with Python?\", \"Can you summarize your key skills?\", \"Tell me about your most recent role.\"]\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
