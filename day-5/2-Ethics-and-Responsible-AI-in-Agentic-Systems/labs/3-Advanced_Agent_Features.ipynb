{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Advanced Agent Features - Multi-Model Usage and Guardrails\n",
    "\n",
    "This lab builds upon our previous multi-agent system and introduces three advanced features of the OpenAI Agents SDK:\n",
    "\n",
    "1.  **Multi-Model Integration**: We will configure our agents to use models from different providers (like Google, DeepSeek, and Groq) instead of just OpenAI.\n",
    "2.  **Structured Outputs**: We'll use Pydantic models to force an agent's output into a specific, predictable JSON structure.\n",
    "3.  **Input Guardrails**: We will implement a safety mechanism to inspect and potentially block a user's prompt before it's processed by the main agent, ensuring responsible AI behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "# Note the new imports from the agents SDK for advanced features.\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Dict\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Core SDK components\n",
    "from agents import Agent, Runner, trace, function_tool\n",
    "\n",
    "# Advanced SDK components for multi-model support and guardrails\n",
    "from agents import OpenAIChatCompletionsModel, input_guardrail, GuardrailFunctionOutput\n",
    "\n",
    "# The standard OpenAI client is now asynchronous for better performance with multiple models.\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# SendGrid for our email tool\n",
    "import sendgrid\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Integrating Multiple Model Providers\n",
    "\n",
    "The OpenAI Agents SDK is designed to be model-agnostic. We can use any model that has an OpenAI-compatible API endpoint. Here, we'll set up clients for DeepSeek, Google's Gemini, and Llama 3 via Groq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === API Key Verification ===\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "print(f\"Google API Key set: {bool(google_api_key)}\")\n",
    "print(f\"DeepSeek API Key set: {bool(deepseek_api_key)}\")\n",
    "print(f\"Groq API Key set: {bool(groq_api_key)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configure Clients and Models for Different Providers ===\n",
    "\n",
    "# We use AsyncOpenAI to create clients pointed at the specific API endpoints for each provider.\n",
    "deepseek_client = AsyncOpenAI(base_url=\"https://api.deepseek.com/v1\", api_key=deepseek_api_key)\n",
    "gemini_client = AsyncOpenAI(base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\", api_key=google_api_key)\n",
    "groq_client = AsyncOpenAI(base_url=\"https://api.groq.com/openai/v1\", api_key=groq_api_key)\n",
    "\n",
    "# We then wrap these clients in an `OpenAIChatCompletionsModel` object.\n",
    "# This allows the Agents SDK to treat them just like a standard OpenAI model.\n",
    "deepseek_model = OpenAIChatCompletionsModel(model=\"deepseek-chat\", openai_client=deepseek_client)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=\"gemini-1.5-flash-latest\", openai_client=gemini_client)\n",
    "llama3_model = OpenAIChatCompletionsModel(model=\"llama3-70b-8192\", openai_client=groq_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Re-define our Sales Agents with the new models ===\n",
    "company_description = \"a company that provides a SaaS tool called 'ComplAI' for ensuring SOC2 compliance and preparing for audits, powered by AI.\"\n",
    "instructions1 = f\"You are a highly professional sales agent for {company_description} You write formal, serious, and benefit-driven cold emails.\"\n",
    "instructions2 = f\"You are a witty and engaging sales agent for {company_description} You write humorous, personable cold emails that are likely to get a response.\"\n",
    "instructions3 = f\"You are a busy, no-nonsense sales agent for {company_description} You write concise, to-the-point cold emails that respect the reader's time.\"\n",
    "\n",
    "# Each agent is now powered by a different model provider.\n",
    "sales_agent1 = Agent(name=\"DeepSeek_Sales_Agent\", instructions=instructions1, model=deepseek_model)\n",
    "sales_agent2 = Agent(name=\"Gemini_Sales_Agent\", instructions=instructions2, model=gemini_model)\n",
    "sales_agent3 = Agent(name=\"Llama3_Sales_Agent\", instructions=instructions3, model=llama3_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Assembling the Agentic Workflow with New Models\n",
    "\n",
    "The rest of our agentic workflow (the tools, the emailer agent, and the manager agent) remains largely the same. We just need to plug our new multi-provider agents into the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define Tools and the Emailer Agent ===\n",
    "\n",
    "# This section is identical to the previous lab, defining the tools needed for the emailer agent.\n",
    "@function_tool\n",
    "def send_html_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "    \"\"\"Sends an email with a subject and HTML body.\"\"\"\n",
    "    FROM_EMAIL = \"your-verified-sender@example.com\"\n",
    "    TO_EMAIL = \"your-recipient@example.com\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    mail = Mail(Email(FROM_EMAIL), To(TO_EMAIL), subject, Content(\"text/html\", html_body))\n",
    "    sg.client.mail.send.post(request_body=mail.get())\n",
    "    return {\"status\": \"success\"}\n",
    "\n",
    "subject_writer = Agent(name=\"Subject_Writer\", instructions=\"You write compelling subjects for cold sales emails.\", model=\"gpt-4o-mini\")\n",
    "subject_tool = subject_writer.as_tool(tool_name=\"subject_writer\", tool_description=\"Writes a subject for an email based on its body.\")\n",
    "\n",
    "html_converter = Agent(name=\"HTML_Converter\", instructions=\"You convert plain text to professional HTML.\", model=\"gpt-4o-mini\")\n",
    "html_tool = html_converter.as_tool(tool_name=\"html_converter\", tool_description=\"Converts a plain text email body to HTML.\")\n",
    "\n",
    "emailer_instructions = \"\"\"You are an email formatting and sending specialist. You receive the body of an email. First, use the `subject_writer` tool to create a subject. Second, use the `html_converter` tool to format the body as HTML. Finally, use the `send_html_email` tool to send the email.\"\"\"\n",
    "emailer_agent = Agent(\n",
    "    name=\"Emailer_Agent\",\n",
    "    instructions=emailer_instructions,\n",
    "    tools=[subject_tool, html_tool, send_html_email],\n",
    "    model=\"gpt-4o\",\n",
    "    handoff_description=\"Takes a plain text email body, formats it, and sends it.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Assemble the Manager's Tools and Handoffs ===\n",
    "\n",
    "# The manager's tools are our new multi-provider agents.\n",
    "tools = [\n",
    "    sales_agent1.as_tool(tool_name=\"deepseek_writer\", tool_description=\"Writes a professional email.\"),\n",
    "    sales_agent2.as_tool(tool_name=\"gemini_writer\", tool_description=\"Writes an engaging email.\"),\n",
    "    sales_agent3.as_tool(tool_name=\"llama_writer\", tool_description=\"Writes a concise email.\")\n",
    "]\n",
    "\n",
    "handoffs = [emailer_agent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Implementing an Input Guardrail\n",
    "\n",
    "A guardrail is a safety check. An **input guardrail** inspects the user's prompt *before* the main agent runs. We will create a guardrail to detect if a personal name is included in the prompt, which might violate privacy or usage policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define a Structured Output for the Guardrail Agent ===\n",
    "# We use a Pydantic model to define the exact JSON structure we want back.\n",
    "class NameCheckOutput(BaseModel):\n",
    "    is_name_in_message: bool\n",
    "    name_found: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define the Guardrail Agent ===\n",
    "# This agent's only job is to check for a name and return a structured response.\n",
    "guardrail_agent = Agent( \n",
    "    name=\"Name_Check_Agent\",\n",
    "    instructions=\"Check if the user's prompt contains a person's first or last name. For example, 'Alice' or 'Smith'. If a name is found, set is_name_in_message to true and return the name.\",\n",
    "    output_type=NameCheckOutput, # This tells the agent to use the Pydantic model for its output.\n",
    "    model=\"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define the Guardrail Function ===\n",
    "# The `@input_guardrail` decorator registers this function as a safety check.\n",
    "# It runs before the main agent logic.\n",
    "\n",
    "@input_guardrail\n",
    "async def guardrail_against_name(ctx, agent, message):\n",
    "    print(\"--- Running Input Guardrail: Checking for names... ---\")\n",
    "    result = await Runner.run(guardrail_agent, message)\n",
    "    \n",
    "    # The `tripwire_triggered` flag tells the Runner to stop execution if it's True.\n",
    "    is_name_present = result.final_output.is_name_in_message\n",
    "    if is_name_present:\n",
    "        print(f\"!!! GUARDRAIL TRIGGERED: Name '{result.final_output.name_found}' found in prompt. Halting execution. !!!\")\n",
    "    else:\n",
    "        print(\"--- Guardrail Passed: No name found. ---\")\n",
    "        \n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info={\"name_check_details\": result.final_output},\n",
    "        tripwire_triggered=is_name_present\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Running the Final, Guarded Workflow\n",
    "\n",
    "Now we create our final Sales Manager agent, this time including the `input_guardrails` parameter. We will then test it with two different prompts: one that should be blocked by the guardrail, and one that should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define the Final, Guarded Manager Agent ===\n",
    "sales_manager_instructions = \"\"\"\n",
    "You are a Sales Manager at ComplAI. Your goal is to find the single best cold sales email using your writer tools, and then hand it off to the Emailer Agent to be sent.\n",
    "\"\"\"\n",
    "\n",
    "careful_sales_manager = Agent(\n",
    "    name=\"Careful_Sales_Manager\",\n",
    "    instructions=sales_manager_instructions,\n",
    "    tools=tools,\n",
    "    handoffs=handoffs,\n",
    "    model=\"gpt-4o\",\n",
    "    input_guardrails=[guardrail_against_name] # Add the guardrail here.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Test 1: This prompt should be BLOCKED by the guardrail ===\n",
    "message_with_name = \"Send out a cold sales email addressed to Dear CEO from Alice\"\n",
    "\n",
    "print(\"--- RUNNING TEST 1 (SHOULD BE BLOCKED) ---\")\n",
    "with trace(\"Guarded_SDR_Blocked\"):\n",
    "    result = await Runner.run(careful_sales_manager, message_with_name)\n",
    "    # Because the guardrail is triggered, the agent's main logic will not execute.\n",
    "    # The `result.final_output` will likely be None or an empty response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Test 2: This prompt should PASS the guardrail ===\n",
    "message_without_name = \"Send out a cold sales email addressed to Dear CEO from the Head of Business Development\"\n",
    "\n",
    "print(\"\\n\\n--- RUNNING TEST 2 (SHOULD PASS) ---\")\n",
    "with trace(\"Guarded_SDR_Passed\"):\n",
    "    result = await Runner.run(careful_sales_manager, message_without_name)\n",
    "    # This time, the full workflow should execute, and an email should be sent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Check\n",
    "\n",
    "Remember to check two places:\n",
    "\n",
    "1.  **The Traces**: [https://platform.openai.com/traces](https://platform.openai.com/traces). Look for the `Guarded_SDR_Blocked` and `Guarded_SDR_Passed` traces. In the first, you'll see the guardrail trigger and halt. In the second, you'll see the full, multi-agent execution.\n",
    "2.  **Your Email Inbox**: To see the final email sent from the successful run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
